{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Testing SHAP and LIME Explanations\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from lime import lime_tabular\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "from data_loader import KerasBinaryClassifier, load_transaction_data, preprocess_data, split_data, train_random_forest\n",
    "from model_explainer import explain_prediction, explain_model, explain_with_lime, plot_lime_explanation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Load models\n",
    "models_dir = 'models'\n",
    "\n",
    "# Load Random Forest\n",
    "rf_model = joblib.load(os.path.join(models_dir, 'rf_model.joblib'))\n",
    "\n",
    "# Load Neural Network\n",
    "keras_model = load_model(os.path.join(models_dir, 'nn_model.h5'))\n",
    "nn_model = KerasBinaryClassifier(model=keras_model, n_features=rf_model.n_features_in_)\n",
    "\n",
    "# Load Ensemble\n",
    "ensemble_model = joblib.load(os.path.join(models_dir, 'ensemble_model.joblib'))\n",
    "\n",
    "print(\"Models loaded successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample transaction created:\n",
      "step: 0.0000\n",
      "customer: 0.0000\n",
      "age: 0.3434\n",
      "gender: 0.0000\n",
      "merchant: 0.0000\n",
      "category: 0.0000\n",
      "amount: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Create a sample transaction\n",
    "feature_names = ['step', 'customer', 'age', 'gender', 'merchant', 'category', 'amount']\n",
    "sample_transaction = np.array([1, 1, 35, 1, 1, 1, 100.0])  # Example values\n",
    "\n",
    "# Normalize the transaction\n",
    "sample_transaction = (sample_transaction - sample_transaction.min()) / (sample_transaction.max() - sample_transaction.min())\n",
    "sample_transaction = sample_transaction.reshape(1, -1)\n",
    "\n",
    "print(\"Sample transaction created:\")\n",
    "for name, value in zip(feature_names, sample_transaction[0]):\n",
    "    print(f\"{name}: {value:.4f}\")\n",
    "\n",
    "# Generate force plot for each model\n",
    "models = {\n",
    "    'Random Forest': rf_model,\n",
    "    'Neural Network': nn_model,\n",
    "    'Ensemble': ensemble_model\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "df = load_transaction_data()\n",
    "df_processed, column_mapping = preprocess_data(df)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = split_data(df_processed)\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf_model = train_random_forest(X_train.values, y_train.values)\n",
    "\n",
    "# Explain a single transaction\n",
    "transaction = X_test.values[0]  # First test transaction\n",
    "feature_names = [col for col in X_test.columns if col != 'fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating force plot for amount...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luqma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 14 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "2025-04-24 17:45:17.710 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-24 17:45:18.863 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\luqma\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-04-24 17:45:18.863 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-24 17:45:18.864 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-24 17:45:18.920 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-24 17:45:18.921 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "An error occurred while generating SHAP explanation: too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\luqma\\OneDrive\\Documents\\GitHub\\DSP-Project\\model_explainer.py:115\u001b[0m, in \u001b[0;36mexplain_prediction\u001b[1;34m(model, transaction, feature_names, background_data, plot_type)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Generate the force plot as HTML\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m force_plot \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforce_plot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpected_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshap_values\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# First sample's SHAP values\u001b[39;49;00m\n\u001b[0;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransaction\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# First sample's feature values\u001b[39;49;00m\n\u001b[0;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatplotlib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m    121\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m force_plot\n",
      "File \u001b[1;32mc:\\Users\\luqma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\shap\\plots\\_force.py:217\u001b[0m, in \u001b[0;36mforce\u001b[1;34m(base_value, shap_values, features, feature_names, out_names, link, plot_cmap, matplotlib, show, figsize, ordering_keys, ordering_keys_time_format, text_rotation, contribution_threshold)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 217\u001b[0m     display_features \u001b[38;5;241m=\u001b[39m \u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    219\u001b[0m instance \u001b[38;5;241m=\u001b[39m Instance(np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(feature_names))), display_features)\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGenerating force plot for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m force_plot \u001b[38;5;241m=\u001b[39m \u001b[43mexplain_prediction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrf_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransaction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforce\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m shap_html \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<head>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshap\u001b[38;5;241m.\u001b[39mgetjs()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m</head><body style=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackground-color: #f0f0f0;\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mforce_plot\u001b[38;5;241m.\u001b[39mhtml()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m</body>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m HTML(shap_html)\n",
      "File \u001b[1;32mc:\\Users\\luqma\\OneDrive\\Documents\\GitHub\\DSP-Project\\model_explainer.py:167\u001b[0m, in \u001b[0;36mexplain_prediction\u001b[1;34m(model, transaction, feature_names, background_data, plot_type)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported plot type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplot_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while generating SHAP explanation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: An error occurred while generating SHAP explanation: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "print(f\"\\nGenerating force plot for {name}...\")\n",
    "force_plot = explain_prediction(\n",
    "    rf_model,\n",
    "    transaction,\n",
    "    feature_names,\n",
    "    plot_type='force'\n",
    ")\n",
    "\n",
    "shap_html = f\"<head>{shap.getjs()}</head><body style='background-color: #f0f0f0;'>{force_plot.html()}</body>\"\n",
    "HTML(shap_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 17:43:57.864 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-24 17:43:57.865 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-24 17:43:57.866 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-24 17:43:57.922 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-24 17:43:57.923 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating force plot for amount...\n",
      "model_id:  1425970237312\n",
      "model_id in _explainer_cache:  1425970237312\n",
      "shap_values:  [[[ 0.02316019 -0.02316019]\n",
      "  [ 0.03884477 -0.03884477]\n",
      "  [ 0.00696927 -0.00696927]\n",
      "  [ 0.00977026 -0.00977026]\n",
      "  [ 0.          0.        ]\n",
      "  [ 0.14340712 -0.14340712]\n",
      "  [ 0.          0.        ]\n",
      "  [ 0.10086992 -0.10086992]\n",
      "  [ 0.17680426 -0.17680426]]]\n",
      "Waterfall plot generated\n",
      "Waterfall:  Figure(1000x600)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"\\nGenerating force plot for {name}...\")\n",
    "waterfall_plot = explain_prediction(\n",
    "    rf_model,\n",
    "    transaction,\n",
    "    feature_names,\n",
    "    plot_type='waterfall'\n",
    ")\n",
    "\n",
    "print(\"Waterfall: \", waterfall_plot)\n",
    "\n",
    "plt.show(waterfall_plot)\n",
    "\n",
    "# shap_html = f\"<head>{shap.getjs()}</head><body style='background-color: #f0f0f0;'>{force_plot.html()}</body>\"\n",
    "# HTML(shap_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating bar plot for Random Forest...\n",
      "model_id:  1426181249776\n",
      "cache_path:  models\\explainers_cache.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 17:43:58.254 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-24 17:43:58.254 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-24 17:43:58.255 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-24 17:43:58.307 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-24 17:43:58.307 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk_cache:  {'random_forest': <shap.explainers._tree.TreeExplainer object at 0x0000014C059F1970>, 'neural_network': <shap.explainers._kernel.KernelExplainer object at 0x0000014C25791730>, 'ensemble': <shap.explainers._kernel.KernelExplainer object at 0x0000014C0F1B7FB0>}\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "An error occurred while generating SHAP explanation: Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. Consider retrying with the feature_perturbation='interventional' option. This check failed because for one of the samples the sum of the SHAP values was 0.744396, while the model output was 1.000000. If this difference is acceptable you can set check_additivity=False to disable this check.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mExplainerError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\luqma\\OneDrive\\Documents\\GitHub\\DSP-Project\\model_explainer.py:102\u001b[0m, in \u001b[0;36mexplain_prediction\u001b[1;34m(model, transaction, feature_names, background_data, plot_type)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m st\u001b[38;5;241m.\u001b[39mspinner(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCalculating SHAP values...\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 102\u001b[0m     shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransaction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m     expected_value \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mexpected_value\n",
      "File \u001b[1;32mc:\\Users\\luqma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\shap\\explainers\\_tree.py:510\u001b[0m, in \u001b[0;36mTreeExplainer.shap_values\u001b[1;34m(self, X, y, tree_limit, approximate, check_additivity, from_call)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_additivity \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel_output \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 510\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_additivity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# This statements handles the case of multiple outputs\u001b[39;00m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;66;03m# e.g. a multi-class classification problem, multi-target regression problem\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;66;03m# in this case the output shape corresponds to [num_samples, num_features, num_outputs]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\luqma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\shap\\explainers\\_tree.py:678\u001b[0m, in \u001b[0;36mTreeExplainer.assert_additivity\u001b[1;34m(self, phi, model_output)\u001b[0m\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(phi)):\n\u001b[1;32m--> 678\u001b[0m         \u001b[43mcheck_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpected_value\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mphi\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\luqma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\shap\\explainers\\_tree.py:674\u001b[0m, in \u001b[0;36mTreeExplainer.assert_additivity.<locals>.check_sum\u001b[1;34m(sum_val, model_output)\u001b[0m\n\u001b[0;32m    671\u001b[0m err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This check failed because for one of the samples the sum of the SHAP values\u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m    672\u001b[0m            \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m was \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msum_val[ind]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124mf\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, while the model output was \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_output[ind]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124mf\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. If this\u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m    673\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m difference is acceptable you can set check_additivity=False to disable this check.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 674\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ExplainerError(err_msg)\n",
      "\u001b[1;31mExplainerError\u001b[0m: Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. Consider retrying with the feature_perturbation='interventional' option. This check failed because for one of the samples the sum of the SHAP values was 0.744396, while the model output was 1.000000. If this difference is acceptable you can set check_additivity=False to disable this check.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGenerating bar plot for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     bar_plot \u001b[38;5;241m=\u001b[39m \u001b[43mexplain_prediction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_transaction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbar\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\luqma\\OneDrive\\Documents\\GitHub\\DSP-Project\\model_explainer.py:205\u001b[0m, in \u001b[0;36mexplain_prediction\u001b[1;34m(model, transaction, feature_names, background_data, plot_type)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported plot type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplot_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while generating SHAP explanation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: An error occurred while generating SHAP explanation: Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. Consider retrying with the feature_perturbation='interventional' option. This check failed because for one of the samples the sum of the SHAP values was 0.744396, while the model output was 1.000000. If this difference is acceptable you can set check_additivity=False to disable this check."
     ]
    }
   ],
   "source": [
    "# Generate bar plot for each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nGenerating bar plot for {name}...\")\n",
    "    bar_plot = explain_prediction(\n",
    "        model,\n",
    "        sample_transaction,\n",
    "        feature_names,\n",
    "        plot_type='bar'\n",
    "    )\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary plot for each model\n",
    "background_data = np.random.rand(100, len(feature_names))\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nGenerating summary plot for {name}...\")\n",
    "    summary_plot = explain_model(\n",
    "        model,\n",
    "        background_data,\n",
    "        feature_names\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "# Generate LIME explanation for each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nGenerating LIME explanation for {name}...\")\n",
    "    lime_explanation = explain_with_lime(\n",
    "        model,\n",
    "        sample_transaction,\n",
    "        feature_names,\n",
    "        num_features=10,\n",
    "        num_samples=5000\n",
    "    )\n",
    "    \n",
    "    # Plot the explanation\n",
    "    plot_lime_explanation(lime_explanation)\n",
    "    \n",
    "    # Print the explanation in text format\n",
    "    print(\"\\nLIME Explanation:\")\n",
    "    print(lime_explanation.as_list())\n",
    "    \n",
    "    # Print prediction probabilities\n",
    "    print(\"\\nPrediction Probabilities:\")\n",
    "    print(f\"Not Fraud: {lime_explanation.predict_proba[0]:.4f}\")\n",
    "    print(f\"Fraud: {lime_explanation.predict_proba[1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
